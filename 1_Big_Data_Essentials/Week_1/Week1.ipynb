{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## File Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2 items\n",
      "drwxr-xr-x   - root supergroup          0 2017-10-15 16:30 /data\n",
      "drwxr-xr-x   - root supergroup          0 2017-10-15 12:23 /user\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "hdfs dfs -ls /"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1 items\r\n",
      "drwxrwxrwx   - jovyan supergroup          0 2017-10-15 16:30 /data/wiki/en_articles_part\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -ls /data/wiki"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73.3 M  /data/wiki\r\n"
     ]
    }
   ],
   "source": [
    "! hdfs dfs -du -h /data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Estimate minimum Namenode RAM size for HDFS with 1 PB capacity, \n",
    "block size 64 MB, average metadata size for each block is 300 B, replication factor is 3. \n",
    "Provide the formula for calculations and the result.\n",
    "\n",
    "RAM: 10 Pb / (128 Mb * 3) * 150 = 3,906,250,000 ~= 3.9Gb\n",
    "# 10000000000000000/(128*3)*150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "\n",
    "Check the formula and the result, they should both be correct.\n",
    "1 PB / 64 MB / 3 * 300 B = 1024 * 1024 * 1024 / 64 / 3 * 300 = 1600 MB\n",
    "\n",
    "The result can not be exactly the same, rounding and other units are possible. So 1600 MB, 1.6 GB, 1.56 GB are all allowed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-14-037e9a206a6e>, line 1)",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-14-037e9a206a6e>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    2) HDDs in your cluster have the following characteristics:\u001b[0m\n\u001b[0m     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ],
     "output_type": "error"
    }
   ],
   "source": [
    "HDDs in your cluster have the following characteristics: \n",
    "    Average reading speed is 60 MB/s, seek time is 5 ms. \n",
    "    You want to spend 0.5% time for seeking the block, \n",
    "    i.e. seek time should be 200 times less than the time to read the block. \n",
    "Estimate the minimum block size.\n",
    "\n",
    "3.5GB/sec → 128Mb : 30-40ms. \n",
    "\n",
    "1Gb = 1000Mb\n",
    "3.5Gb = 3500Mb\n",
    "1 second = 1000 millisecond\n",
    "\n",
    "3500Mb = 1sec\n",
    "128Mb = (32/875)sec = 0.03657 sec\n",
    "\n",
    "1 second = 1000 millisecond\n",
    "0.03657 sec = 36.57 millisecond"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution\n",
    "Check the calculations and the result, they should both be correct.\n",
    "\n",
    "block_size / 60 MB/s * 0.5 / 100 >= 5 ms\n",
    "block_size >= 60 MB/s * 0.005 s / 0.005 = 60 MB\n",
    "\n",
    "So, the minimum block size is 60 MB or 64 MB."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Create text file ‘test.txt’ in a local fs. Use HDFS CLI to make the following operations:\n",
    "\n",
    "Create directory ‘assignment1’ in your home directory in HDFS (/user/<your_name>)\n",
    "put test.txt in it\n",
    "output the size and the owner of the file\n",
    "revoke ‘read’ permission for ‘other users’\n",
    "read the first 10 lines of the file\n",
    "rename it to ‘test2.txt’.\n",
    "Provide all the commands to HDFS CLI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "\n",
    "# In local file system create test.txt\n",
    "touch text.txt\n",
    "\n",
    "#сreate directory ‘assignment1’ in your home directory in HDFS (/user/<your_name>)\n",
    "hdfs dfs -mkdir -p '/user/jovyan/assignment1'\n",
    "\n",
    "# put test.txt in it\n",
    "hdfs dfs -put 'text.txt' '/user/jovyan/assignment1/text.txt'\n",
    "\n",
    "# output the size and the owner of the file\n",
    "hdfs dfs -ls -h '/user/jovyan/assignment1/text.txt'\n",
    "\n",
    "# revoke ‘read’ permission for ‘other users’\n",
    "hdfs dfs -chmod o-r '/user/jovyan/assignment1/text.txt'\n",
    "\n",
    "# read the first 10 lines of the file\n",
    "hdfs dfs -cat '/user/jovyan/assignment1/text.txt' | head -10\n",
    "\n",
    "# rename it to ‘test2.txt’\n",
    "hdfs dfs -mv '/user/jovyan/assignment1/text.txt' '/user/jovyan/assignment1/text2.txt'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Use HDFS CLI to investigate the file ‘/data/wiki/en_articles_part/articles-part’ in HDFS:\n",
    "\n",
    "- Get blocks and their locations in HDFS for this file, show the command without an output\n",
    "- Get the information about any block of the file, show the command and the block locations from the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "    \n",
    "Blocks and locations of ‘/data/wiki/en_articles_part/articles-part’:\n",
    "$ hdfs fsck /data/wiki/en_articles_part/articles-part -files -blocks -locations\n",
    "\n",
    "Block information (block id may be different):\n",
    "$ hdfs fsck -blockId blk_1073971670\n",
    "\n",
    "It outputs the block locations, example (nodes list will be different):\n",
    "Block replica on datanode/rack: some_node_hostname/default-rack is HEALTHY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Look at the picture of Namenode web interface.\n",
    "Show the total capacity of this HDFS installation, used space and total data nodes in the cluster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "    \n",
    "1) Total capacity of this HDFS installation: \n",
    "    Configured Capacity: 2.14TB\n",
    "2) Used space: \n",
    "    DFS used: 242.12 Gb\n",
    "3) Total data nodes in the cluster:\n",
    "    Live Nodes: 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
